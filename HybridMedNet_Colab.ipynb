{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# HybridMedNet - 医学影像深度学习诊断框架\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alltobebetter/HybridMedNet/blob/main/HybridMedNet_Colab.ipynb)\n",
                "\n",
                "一键运行医学影像分类训练"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 环境设置"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 检查 GPU\n",
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\nPyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 克隆项目\n",
                "import os\n",
                "if not os.path.exists('HybridMedNet'):\n",
                "    !git clone https://github.com/alltobebetter/HybridMedNet.git\n",
                "    print(\"[OK] 项目克隆完成\")\n",
                "else:\n",
                "    print(\"[OK] 项目已存在\")\n",
                "\n",
                "%cd HybridMedNet"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 安装依赖"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q timm albumentations einops\n",
                "!pip install -q pandas matplotlib seaborn scikit-learn tqdm\n",
                "print(\"[OK] 依赖安装完成\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 选择数据集\n",
                "\n",
                "### 选项 A: 使用示例数据（快速测试）\n",
                "### 选项 B: 下载真实医学数据集（推荐）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 选择数据集类型\n",
                "USE_REAL_DATASET = True  # True=真实数据集, False=示例数据\n",
                "\n",
                "if USE_REAL_DATASET:\n",
                "    print(\"将使用真实医学数据集\")\n",
                "else:\n",
                "    print(\"将使用示例数据集（快速测试）\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 下载真实数据集：胸部 X 光肺炎数据集\n",
                "\n",
                "- 数据集: Chest X-Ray Pneumonia\n",
                "- 大小: ~1.2 GB\n",
                "- 图像数: 5,863 张\n",
                "- 类别: Normal / Pneumonia\n",
                "- 来源: Kaggle\n",
                "\n",
                "**如何获取 Kaggle API key:**\n",
                "1. 访问 https://www.kaggle.com/settings\n",
                "2. 点击 'Create New API Token'\n",
                "3. 下载 kaggle.json\n",
                "4. 运行下面的 cell 上传文件"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 上传 Kaggle API key（如果需要）\n",
                "if USE_REAL_DATASET:\n",
                "    import os\n",
                "    if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
                "        print(\"请上传 kaggle.json 文件\")\n",
                "        print(\"如果没有，可以跳过此步骤，将使用示例数据\\n\")\n",
                "        \n",
                "        from google.colab import files\n",
                "        uploaded = files.upload()\n",
                "        \n",
                "        if 'kaggle.json' in uploaded:\n",
                "            !mkdir -p ~/.kaggle\n",
                "            !cp kaggle.json ~/.kaggle/\n",
                "            !chmod 600 ~/.kaggle/kaggle.json\n",
                "            print(\"[OK] Kaggle API key 已配置\")\n",
                "        else:\n",
                "            print(\"[INFO] 未上传 kaggle.json，将尝试其他下载方式\")\n",
                "    else:\n",
                "        print(\"[OK] Kaggle API key 已存在\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if USE_REAL_DATASET:\n",
                "    print(\"正在下载真实数据集...\")\n",
                "    print(\"这可能需要 5-10 分钟，请耐心等待\\n\")\n",
                "    \n",
                "    import os\n",
                "    \n",
                "    # 检查是否有 kaggle.json\n",
                "    if os.path.exists('/root/.kaggle/kaggle.json'):\n",
                "        print(\"使用 Kaggle API 下载...\\n\")\n",
                "        !pip install -q kaggle\n",
                "        !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
                "        \n",
                "        print(\"\\n解压数据集...\")\n",
                "        !unzip -q chest-xray-pneumonia.zip -d ./data/\n",
                "        !rm chest-xray-pneumonia.zip\n",
                "        \n",
                "        # 查找数据目录\n",
                "        if os.path.exists('./data/chest_xray/train'):\n",
                "            data_dir = './data/chest_xray/train'\n",
                "        elif os.path.exists('./data/train'):\n",
                "            data_dir = './data/train'\n",
                "        else:\n",
                "            print(\"[WARNING] 未找到训练数据目录\")\n",
                "            data_dir = None\n",
                "        \n",
                "        if data_dir:\n",
                "            print(f\"\\n[OK] 数据集下载完成\")\n",
                "            print(f\"数据位置: {data_dir}\")\n",
                "            !ls -lh {data_dir}\n",
                "            labels_file = None\n",
                "        else:\n",
                "            print(\"\\n[INFO] 下载失败，将使用示例数据\")\n",
                "            data_dir = None\n",
                "            labels_file = None\n",
                "    else:\n",
                "        print(\"[WARNING] 未检测到 Kaggle API key\")\n",
                "        print(\"请先运行上面的 cell 上传 kaggle.json\")\n",
                "        print(\"或者设置 USE_REAL_DATASET = False 使用示例数据\\n\")\n",
                "        data_dir = None\n",
                "        labels_file = None\n",
                "        \n",
                "else:\n",
                "    print(\"跳过真实数据集下载\")\n",
                "    data_dir = None\n",
                "    labels_file = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 准备数据和配置"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 导入必要模块\n",
                "import sys\n",
                "sys.path.insert(0, os.getcwd())\n",
                "\n",
                "from data.chest_xray_dataset import create_sample_dataset, ChestXrayDataset\n",
                "from data.transforms import get_train_transforms, get_val_transforms\n",
                "from models.hybrid_med_net import HybridMedNet\n",
                "from configs.default_config import Config\n",
                "from utils.metrics import calculate_metrics\n",
                "\n",
                "print(\"[OK] 模块导入成功\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 如果没有使用真实数据集，创建示例数据\n",
                "if not USE_REAL_DATASET or data_dir is None:\n",
                "    print(\"创建示例数据集...\")\n",
                "    data_dir = './data/sample_chest_xray'\n",
                "    data_dir, labels_file = create_sample_dataset(data_dir, num_samples=200)\n",
                "    print(f\"[OK] 示例数据集创建完成: {data_dir}\")\n",
                "else:\n",
                "    print(f\"[OK] 使用真实数据集: {data_dir}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 配置模型\n",
                "config = Config()\n",
                "config.DATA['data_dir'] = data_dir\n",
                "config.DATA['labels_file'] = labels_file\n",
                "config.DATA['num_workers'] = 2\n",
                "config.MODEL['hierarchical'] = False\n",
                "\n",
                "# 根据数据集类型调整配置\n",
                "if USE_REAL_DATASET:\n",
                "    # 真实数据集配置\n",
                "    config.TRAIN['batch_size'] = 32\n",
                "    config.TRAIN['epochs'] = 20  # 真实数据需要更多轮次\n",
                "    config.MODEL['backbone'] = 'resnet50'\n",
                "    config.MODEL['num_classes'] = 2  # Normal / Pneumonia\n",
                "    print(\"使用真实数据集配置\")\n",
                "else:\n",
                "    # 示例数据配置\n",
                "    config.TRAIN['batch_size'] = 16\n",
                "    config.TRAIN['epochs'] = 10\n",
                "    config.MODEL['backbone'] = 'resnet50'\n",
                "    config.MODEL['num_classes'] = 14  # 14 种疾病\n",
                "    print(\"使用示例数据配置\")\n",
                "\n",
                "config.TRAIN['mixed_precision'] = True\n",
                "\n",
                "print(\"\\n配置信息:\")\n",
                "print(f\"  数据目录: {config.DATA['data_dir']}\")\n",
                "print(f\"  类别数: {config.MODEL['num_classes']}\")\n",
                "print(f\"  Backbone: {config.MODEL['backbone']}\")\n",
                "print(f\"  Batch size: {config.TRAIN['batch_size']}\")\n",
                "print(f\"  Epochs: {config.TRAIN['epochs']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 加载数据"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import DataLoader\n",
                "from torchvision import datasets\n",
                "from tqdm.notebook import tqdm\n",
                "import numpy as np\n",
                "\n",
                "# 根据数据集类型选择加载方式\n",
                "if USE_REAL_DATASET and labels_file is None:\n",
                "    # 使用 ImageFolder 加载文件夹结构的数据\n",
                "    print(\"使用文件夹结构加载数据...\")\n",
                "    \n",
                "    train_dataset = datasets.ImageFolder(\n",
                "        root=config.DATA['data_dir'],\n",
                "        transform=get_train_transforms(config.DATA['image_size'])\n",
                "    )\n",
                "    \n",
                "    # 使用验证集或测试集\n",
                "    val_dir = config.DATA['data_dir'].replace('train', 'val')\n",
                "    if not os.path.exists(val_dir):\n",
                "        val_dir = config.DATA['data_dir'].replace('train', 'test')\n",
                "    \n",
                "    val_dataset = datasets.ImageFolder(\n",
                "        root=val_dir,\n",
                "        transform=get_val_transforms(config.DATA['image_size'])\n",
                "    )\n",
                "    \n",
                "    print(f\"类别: {train_dataset.classes}\")\n",
                "    \n",
                "else:\n",
                "    # 使用 CSV 标签文件加载\n",
                "    print(\"使用 CSV 标签文件加载数据...\")\n",
                "    \n",
                "    train_dataset = ChestXrayDataset(\n",
                "        data_dir=config.DATA['data_dir'],\n",
                "        labels_file=config.DATA['labels_file'],\n",
                "        transform=get_train_transforms(config.DATA['image_size']),\n",
                "        split='train'\n",
                "    )\n",
                "    \n",
                "    val_dataset = ChestXrayDataset(\n",
                "        data_dir=config.DATA['data_dir'],\n",
                "        labels_file=config.DATA['labels_file'],\n",
                "        transform=get_val_transforms(config.DATA['image_size']),\n",
                "        split='val'\n",
                "    )\n",
                "\n",
                "# 创建数据加载器\n",
                "train_loader = DataLoader(\n",
                "    train_dataset,\n",
                "    batch_size=config.TRAIN['batch_size'],\n",
                "    shuffle=True,\n",
                "    num_workers=config.DATA['num_workers']\n",
                ")\n",
                "\n",
                "val_loader = DataLoader(\n",
                "    val_dataset,\n",
                "    batch_size=config.TRAIN['batch_size'],\n",
                "    shuffle=False,\n",
                "    num_workers=config.DATA['num_workers']\n",
                ")\n",
                "\n",
                "print(f\"\\n[OK] 数据加载完成\")\n",
                "print(f\"训练集: {len(train_dataset)} 张\")\n",
                "print(f\"验证集: {len(val_dataset)} 张\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 训练模型"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 创建模型\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model = HybridMedNet(config).to(device)\n",
                "\n",
                "# 损失函数和优化器\n",
                "if USE_REAL_DATASET:\n",
                "    # 单标签分类（交叉熵）\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    is_multilabel = False\n",
                "else:\n",
                "    # 多标签分类（BCE）\n",
                "    criterion = nn.BCEWithLogitsLoss()\n",
                "    is_multilabel = True\n",
                "\n",
                "optimizer = torch.optim.AdamW(\n",
                "    model.parameters(),\n",
                "    lr=config.TRAIN['learning_rate'],\n",
                "    weight_decay=config.TRAIN['weight_decay']\n",
                ")\n",
                "\n",
                "print(f\"[OK] 模型已创建\")\n",
                "print(f\"设备: {device}\")\n",
                "print(f\"分类类型: {'多标签' if is_multilabel else '单标签'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 训练循环\n",
                "best_val_loss = float('inf')\n",
                "train_losses = []\n",
                "val_losses = []\n",
                "\n",
                "print(\"\\n开始训练...\\n\")\n",
                "\n",
                "for epoch in range(config.TRAIN['epochs']):\n",
                "    # 训练阶段\n",
                "    model.train()\n",
                "    train_loss = 0.0\n",
                "    \n",
                "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.TRAIN['epochs']} [Train]\")\n",
                "    for images, labels in pbar:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        train_loss += loss.item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    train_loss /= len(train_loader)\n",
                "    train_losses.append(train_loss)\n",
                "    \n",
                "    # 验证阶段\n",
                "    model.eval()\n",
                "    val_loss = 0.0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.TRAIN['epochs']} [Val]\", leave=False):\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            val_loss += loss.item()\n",
                "    \n",
                "    val_loss /= len(val_loader)\n",
                "    val_losses.append(val_loss)\n",
                "    \n",
                "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
                "    \n",
                "    # 保存最佳模型\n",
                "    if val_loss < best_val_loss:\n",
                "        best_val_loss = val_loss\n",
                "        torch.save(model.state_dict(), 'best_model.pth')\n",
                "        print(f\"  -> 保存最佳模型 (Val Loss: {val_loss:.4f})\")\n",
                "\n",
                "print(\"\\n[OK] 训练完成\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. 可视化训练过程"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(train_losses, label='Train Loss', marker='o')\n",
                "plt.plot(val_losses, label='Val Loss', marker='s')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.title('Training and Validation Loss')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. 评估模型"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import roc_auc_score\n",
                "\n",
                "# 加载最佳模型\n",
                "model.load_state_dict(torch.load('best_model.pth'))\n",
                "model.eval()\n",
                "\n",
                "# 收集预测结果\n",
                "all_preds = []\n",
                "all_labels = []\n",
                "\n",
                "print(\"评估模型...\")\n",
                "with torch.no_grad():\n",
                "    for images, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
                "        images = images.to(device)\n",
                "        outputs = model(images)\n",
                "        preds = torch.sigmoid(outputs).cpu().numpy()\n",
                "        \n",
                "        all_preds.append(preds)\n",
                "        all_labels.append(labels.numpy())\n",
                "\n",
                "all_preds = np.vstack(all_preds)\n",
                "all_labels = np.vstack(all_labels)\n",
                "\n",
                "# 计算指标\n",
                "all_preds_binary = (all_preds > 0.5).astype(int)\n",
                "metrics = calculate_metrics(all_labels, all_preds_binary, all_preds)\n",
                "\n",
                "print(\"\\n评估结果:\")\n",
                "print(f\"准确率: {metrics['accuracy']:.4f}\")\n",
                "print(f\"精确率: {metrics['precision']:.4f}\")\n",
                "print(f\"召回率: {metrics['recall']:.4f}\")\n",
                "print(f\"F1分数: {metrics['f1_score']:.4f}\")\n",
                "print(f\"平均AUC: {metrics.get('auc', 0.0):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. 预测示例"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from PIL import Image\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# 获取示例图像\n",
                "sample_images = [os.path.join(config.DATA['data_dir'], f) \n",
                "                 for f in os.listdir(config.DATA['data_dir']) \n",
                "                 if f.endswith(('.jpg', '.png'))][:3]\n",
                "\n",
                "class_names = train_dataset.class_names\n",
                "\n",
                "for img_path in sample_images:\n",
                "    image = Image.open(img_path).convert('RGB')\n",
                "    \n",
                "    # 预处理\n",
                "    transform = get_val_transforms(config.DATA['image_size'])\n",
                "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
                "    \n",
                "    # 预测\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        output = model(image_tensor)\n",
                "        probs = torch.sigmoid(output).cpu().numpy()[0]\n",
                "    \n",
                "    # 显示结果\n",
                "    plt.figure(figsize=(12, 4))\n",
                "    \n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.imshow(image)\n",
                "    plt.title(f'Input: {os.path.basename(img_path)}')\n",
                "    plt.axis('off')\n",
                "    \n",
                "    plt.subplot(1, 2, 2)\n",
                "    y_pos = np.arange(len(class_names))\n",
                "    plt.barh(y_pos, probs)\n",
                "    plt.yticks(y_pos, class_names, fontsize=8)\n",
                "    plt.xlabel('Probability')\n",
                "    plt.title('Predictions')\n",
                "    plt.xlim([0, 1])\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # Top-3 预测\n",
                "    top3_idx = np.argsort(probs)[-3:][::-1]\n",
                "    print(f\"Top-3 预测:\")\n",
                "    for idx in top3_idx:\n",
                "        print(f\"  {class_names[idx]}: {probs[idx]:.2%}\")\n",
                "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 总结\n",
                "\n",
                "完成的任务:\n",
                "1. 环境设置和依赖安装\n",
                "2. 创建示例数据集\n",
                "3. 训练模型\n",
                "4. 评估性能\n",
                "5. 预测示例图像\n",
                "\n",
                "模型已保存到: `best_model.pth`\n",
                "\n",
                "### 下一步\n",
                "\n",
                "- 尝试不同的 backbone: `config.MODEL['backbone'] = 'convnext_base'`\n",
                "- 增加训练轮数: `config.TRAIN['epochs'] = 50`\n",
                "- 使用真实医学数据集进行训练\n",
                "\n",
                "### 资源链接\n",
                "\n",
                "- [项目 GitHub](https://github.com/alltobebetter/HybridMedNet)\n",
                "- [完整文档](https://github.com/alltobebetter/HybridMedNet/blob/main/README.md)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
